# Step 0: 環境構築詳細メモ

## 目的
- 強化学習アルゴリズムから扱いやすい OthelloEnv を作る
- 後工程 (Q-learning / DQN / AlphaZero) で改造しやすい構造に

## 設計ポイント再掲
1. 行動空間 = size*size + 1 (pass)
2. 観測チャネル = [自石, 相手石, 合法手] (視点正規化)
3. 終局条件 = 二連続 pass or 両者合法手無し
4. 報酬 = 終局: 勝ち+1/負け-1/引分0 (中間報酬なし)
5. 不正手防止 = 学習時にはマスク利用 (環境内部では不正手なら終了 or 例外)

## 今後の拡張予定
- 対称性データ拡張
- ビットボード化
- MCTS 用 局面キャッシュ (Zobrist Hash)
- ベンチマーク / ログ (TensorBoard, WandB)
